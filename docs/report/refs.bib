
@misc{aberdam_clipter_2023,
	title = {{CLIPTER}: {Looking} at the {Bigger} {Picture} in {Scene} {Text} {Recognition}},
	shorttitle = {{CLIPTER}},
	url = {http://arxiv.org/abs/2301.07464},
	doi = {10.48550/arXiv.2301.07464},
	abstract = {Reading text in real-world scenarios often requires understanding the context surrounding it, especially when dealing with poor-quality text. However, current scene text recognizers are unaware of the bigger picture as they operate on cropped text images. In this study, we harness the representative capabilities of modern vision-language models, such as CLIP, to provide scene-level information to the crop-based recognizer. We achieve this by fusing a rich representation of the entire image, obtained from the vision-language model, with the recognizer word-level features via a gated cross-attention mechanism. This component gradually shifts to the context-enhanced representation, allowing for stable fine-tuning of a pretrained recognizer. We demonstrate the effectiveness of our model-agnostic framework, CLIPTER (CLIP TExt Recognition), on leading text recognition architectures and achieve state-of-the-art results across multiple benchmarks. Furthermore, our analysis highlights improved robustness to out-of-vocabulary words and enhanced generalization in low-data regimes.},
	urldate = {2025-03-03},
	publisher = {arXiv},
	author = {Aberdam, Aviad and Bensa√Ød, David and Golts, Alona and Ganz, Roy and Nuriel, Oren and Tichauer, Royee and Mazor, Shai and Litman, Ron},
	month = jul,
	year = {2023},
	note = {arXiv:2301.07464 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {Preprint PDF:C\:\\Users\\Riley\\Zotero\\storage\\5TFGLFAE\\Aberdam et al. - 2023 - CLIPTER Looking at the Bigger Picture in Scene Text Recognition.pdf:application/pdf;Snapshot:C\:\\Users\\Riley\\Zotero\\storage\\Y39JSZBT\\2301.html:text/html},
}
